抄録
畳み込みニューラルネットワークを用いた単一画像の超解像の精度と速度が飛躍的に向上しているにもかかわらず、1つの中心的な問題がほとんど解決されていません：大きなアップスケーリング係数で超解像を行う際に、どのようにしてより微細なテクスチャの詳細を回復するか？最適化ベースの超解像手法の動作は、主に目的関数の選択によって決まります。最近の研究では、主に平均二乗再構成誤差の最小化に焦点が当てられています。結果として得られる推定値は高いピークS/N比を持つが、高周波数の詳細が欠けていることが多く、より高い解像度で期待される忠実度と一致しないという意味で、知覚的には満足できないものとなっている。本論文では、画像超解像（SR）のための生成的逆境ネットワーク（GAN）であるSRGANを提案する。本論文では、SRGANを用いて、4倍のアップスケーリングファクターでフォトリアリスティックな自然画像を推論することができる初めてのフレームワークを提案する。これを実現するために、我々は知覚損失関数を提案している。逆説的損失は、超解像画像と元のフォトリアリスティック画像を区別するために訓練された識別ネットワークを用いて、我々の解を自然画像の多様体に押し付ける。さらに、ピクセル空間の類似度ではなく、知覚的類似度に動機づけられたコンテンツロスを使用しています。我々のディープ残差ネットワークは、公開されているベンチマーク上で、ダウンサンプリングされた画像から写真のようにリアルなテクスチャを復元することができる。広範なMOS(mean-opinion-score)テストでは、SRGANを用いて知覚品質が大幅に向上していることが示されています。SRGANを用いて得られたMOSスコアは、最先端の手法を用いて得られたものよりも、元の高解像度画像のMOSスコアに近いものであった。

1. 序章
低解像度(LR)画像から高解像度(HR)画像を推定するという非常に困難な課題を超解像(SR)と呼ぶ。超解像（SR）は、コンピュータビジョン研究コミュニティの中で大きな注目を集めており、幅広い応用が可能である [63, 71, 43]。

4×SRGAN(提案) オリジナル 図1: 超解像画像(左)はオリジナル画像(右)とほとんど区別がつかない。4×アップスケーリング

特に、再構成されたSR画像には一般的にテクスチャの詳細が存在しないような、高いアップスケーリング係数の場合には、この問題の課題は顕著になります。教師付きSRアルゴリズムの最適化目標は、一般的に、復元されたHR画像と基底真理値との間の平均二乗誤差（MSE）を最小化することです。MSEを最小化すると、SRアルゴリズムの評価や比較に使用される一般的な指標であるピークS/N比（PSNR）も最大化されるため、これは便利です[61]。しかし、MSE（およびPSNR）はピクセル単位の画像差分に基づいて定義されているため、高いテクスチャの詳細などの知覚的に関連する差分をキャプチャする能力は非常に限られています[60, 58, 26]。これは図2に示されており、最高のPSNRが必ずしも知覚的に優れたSR結果を反映しているわけではありません。超解像された画像と元の画像の間に知覚的な違いがあるということは、Ferwerda[16]で定義されているように、復元された画像はフォトリアリスティックではないことを意味します。本研究では、超解像生成的逆境ネットワーク(SRGAN)を提案する。このネットワークでは、スキップコネクションを持つディープ残差ネットワーク(ResNet)を採用し、MSEからの発散を唯一の最適化対象とする。これまでの研究とは異なり、我々はVGGネットワークの高レベル特徴マップ[49, 33, 5]と、HR基準画像と知覚的に区別しにくい解を促す識別器を組み合わせて、新しい知覚的損失を定義しています。図1に、4×のアップスケーリング係数で超解像されたフォトリアリスティックな画像の例を示します。

図2：左から順に、二分補間、MSEに最適化された深層残差ネットワーク、人間の知覚により敏感な損失に最適化された深層残差生成逆説ネットワーク、元のHR画像。対応するPSNRとSSIMは括弧内に示しています。4×アップスケーリング

1.1. 関連作業
1.1.1 画像の超解像
画像の超解像に関する最近の概観記事には、Nasrollahi and Moeslund [43] や Yang et al. ここでは、単一画像の超解像（SISR）に焦点を当て、複数の画像から HR 画像を復元するアプローチについては、ここでは触れないことにする [4, 15]。予測ベースの手法は、SISRに取り組む最初の手法の一つである。これらのフィルタリング手法、例えば線形フィルタリング、二重曲線フィルタリング、Lanczos [14] フィルタリングは非常に高速であるが、SISR問題を単純化しすぎており、通常は過度に滑らかなテクスチャを用いた解が得られる。特にエッジ保存に重点を置いた手法が提案されています[1, 39]。より強力なアプローチは、低解像度と高解像度の画像情報間の複雑なマッピングを確立することを目的としており、通常はトレーニングデータに依存しています。例対に基づく多くの手法は、対応するHR対応が既知のLRトレーニングパッチに依存している。初期の研究はFreemanら[18, 17]によって発表された。SR問題への関連アプローチは、圧縮センシング[62, 12, 69]に由来する。Glasnerら[21]では、著者らはSRを駆動するために画像内のスケール間のパッチの冗長性を利用しています。この自己相似性のパラダイムは，Huangら[31]でも採用されており，ここでは，小さな変換や形状変化をさらに許容することで，自己辞書を拡張している．Guら[25]は、重ね合わせたパッチではなく画像全体を処理することで一貫性を向上させる畳み込みスパース符号化アプローチを提案している。エッジアーチファクトを回避しながら現実的なテクスチャの詳細を再構成するために、Taiら[52]は、勾配プロファイル先行[50]に基づくエッジ指向SRアルゴリズムと学習ベースの詳細合成の利点を組み合わせている。Zhangら[70]は，類似した画像パッチの冗長性を異なるスケールで捉えるためのマルチスケール辞書を提案している．ランドマーク画像を超解像するために，Yueら[67]は，ウェブから類似したコンテンツを持つ相関のあるHR画像を取得し，アライメントのための構造を考慮したマッチング基準を提案している．近傍埋め込みアプローチは、低次元の多様体の中から類似したLR学習パッチを見つけ出し、その対応するHRパッチを組み合わせて再構成することでLR画像パッチをアップサンプルする[54, 55]。Kim and Kwon [35]では、著者らは近傍埋め込みアプローチがオーバーフィットする傾向を強調し、カーネルリッジ回帰を用いて例のペアのより一般的なマップを定式化している。回帰問題は、ガウス過程回帰[27]、木[46]またはランダムフォレスト[47]でも解くことができる。Daiら[6]では、多数のパッチ固有の回帰器が学習され、テスト中に最も適切な回帰器が選択される。最近では畳み込みニューラルネットワーク（CNN）ベースのSRアルゴリズムが優れた性能を示している。Wang et al. [59]では、著者らは、学習された反復的収縮・閾値アルゴリズム（LISTA）[23]に基づいて、フィードフォワードネットワークアーキテクチャに、疎な表現を事前にエンコードしている。Dongら[9, 10]は、入力画像をアップスケールするために二重補間を使用し、3層の深層完全畳み込みネットワークをエンドツーエンドで訓練して、最先端のSR性能を達成した。その後、ネットワークがアップスケーリングフィルタを直接学習できるようにすることで、精度と速度の両面で性能がさらに向上することが示された[11, 48, 57]。Kimら[34]は、深部再帰的畳み込みネットワーク（DRCN）を用いて、モデルパラメータの数を少なくしながら、長距離のピクセル依存性を可能にする高性能なアーキテクチャを発表した。我々の論文に特に関連するのは、Johnsonら[33]とBrunaら[5]の研究であり、彼らは知覚的類似性に近い損失関数に依存して、視覚的に説得力のあるHR画像を回復している。

1.1.2 畳み込みニューラルネットワークの設計
一方、多くのコンピュータビジョン問題に対する最先端の技術は、Krizhevskyら[37]の研究の成功を受けて、特別に設計されたCNNアーキテクチャによって設定されている。深層ネットワークアーキテクチャは訓練が困難であるが，非常に複雑なマッピングのモデリングを可能にするため，ネットワークの精度を大幅に向上させる可能性があることが示された[49, 51]．これらのより深いネットワーク・アーキテクチャを効率的に訓練するために、内部の共変量シフトを打ち消すためにバッチ正規化[32]がしばしば使用される。より深いネットワークアーキテクチャはSISRの性能を向上させることも示されており、例えばKimら[34]は再帰的CNNを定式化し、最新の結果を提示している。ディープCNNの学習を容易にするもう一つの強力な設計選択は、最近導入された残差ブロック[29]とスキップコネクショ ン[30, 34]の概念である。スキップコネクショ ンは、本質的には些細なことであるが、畳み込みカーネルを使って表現するにはトリビアルではない可能性がある同一性写像をモデル化するというネットワークアーキテクチャから解放される。SISRのコンテキストでは、アップスケーリングフィルタを学習することが精度と速度の面で有益であることも示されています[11, 48, 57]。これは、画像をCNNに供給する前にLR観測をアップスケールするために二重立方補間を採用しているDongら[10]よりも改善されたものである。

1.1.3 損失関数 MSE のようなピクセル単位の損失関数は，テクスチャのような失われた高周波数の詳細を復元する際に内在する不確実性を処理するのに苦労します：MSE を最小化することは，典型的には過度に滑らかであるために知覚的な品質が劣る，もっともらしい解のピクセル単位の平均を見つけることを奨励します [42, 33, 13, 5]．知覚的品質を変化させた再構成を、対応するPSNRとともに図2に例示します。我々は、滑らかな再構成を作成するために、テクスチャの詳細度が高い複数の潜在的な解を平均化する図3のMSEを最小化する問題を説明しています。Mathieu et al. [42] と Denton et al. [7]では、画像生成のアプリケーションにGANs (Generative adversarial networks) [22]を採用することで、この問題に取り組んでいます。Yu and Porikli [66] は，ピクセル単位の MSE 損失を識別器損失で増強し，大きな拡大率（8×）の顔画像を超解像するネットワークを学習した．GANはRadfordら[44]で教師なし表現学習にも利用されている．GANを使用して1つの多様体から別の多様体への写像を学習するというアイデアは、Li and Wand [38]ではスタイル伝達のために、Yehら[64]ではインペインティングのために記述されています。Brunaら[5]は、VGG19[49]と散乱ネットワークの特徴空間における二乗誤差を最小化している。Dosovitskiy and Brox [13]は、ニューラルネットワークの特徴空間で計算されたユークリッド距離に基づく損失関数を、敵対的訓練と組み合わせて使用している。提案された損失が視覚的に優れた画像生成を可能にし、非線形特徴表現の復号という難問である逆問題を解決するために使用できることが示されている。この研究と同様に、Johnsonら[33]とBrunaら[5]は、低レベルのピクセル単位の誤差測定値の代わりに、事前に訓練されたVGGネットワークから抽出された特徴量を使用することを提案している。具体的には、著者らはVGG19 [49]ネットワークから抽出された特徴マップ間のユークリッド距離に基づいて損失関数を定式化している。超解像と芸術的スタイル伝達の両方において、知覚的により説得力のある結果が得られている[19, 20]。最近では、LiとWand[38]もまた、ピクセルまたはVGG特徴空間におけるパッチの比較とブレンドの効果を調査した。

図3：自然画像マニホールドからのパッチ（赤）と、MSE（青）とGAN（オレンジ）で得られた超解像パッチのイラスト。MSEベースの解は、ピクセル空間で可能な解のピクセル単位の平均値のため、過度に滑らかに見えますが、GANは再構成を自然画像マニホールドに向けて駆動し、知覚的により説得力のある解を生み出します。

1.1.3 損失関数
MSE のようなピクセル単位の損失関数は、テクスチャのような失われた高周波数の詳細を復元する際に内在する不確実性を処理するのに苦労します: MSE を最小化することは、典型的には過度に滑らかであるために知覚品質が低い妥当な解のピクセル単位の平均を見つけることを奨励します [42, 33, 13, 5]。知覚的品質を変化させた再構成を、対応するPSNRとともに図2に例示します。我々は、滑らかな再構成を作成するために、テクスチャの詳細度が高い複数の潜在的な解を平均化する図3のMSEを最小化する問題を説明しています。Mathieu et al. [42] と Denton et al. [7]では、画像生成のアプリケーションにGANs (Generative adversarial networks) [22]を採用することで、この問題に取り組んでいます。Yu and Porikli [66] は，ピクセル単位の MSE 損失を識別器損失で増強し，大きな拡大率（8×）の顔画像を超解像するネットワークを学習した．GANはRadfordら[44]で教師なし表現学習にも利用されている．GANを使用して1つの多様体から別の多様体への写像を学習するというアイデアは、Li and Wand [38]ではスタイル伝達のために、Yehら[64]ではインペインティングのために記述されています。Brunaら[5]は、VGG19[49]と散乱ネットワークの特徴空間における二乗誤差を最小化している。Dosovitskiy and Brox [13]は、ニューラルネットワークの特徴空間で計算されたユークリッド距離に基づく損失関数を、敵対的訓練と組み合わせて使用している。提案された損失が視覚的に優れた画像生成を可能にし、非線形特徴表現の復号という難問である逆問題を解決するために使用できることが示されている。この研究と同様に、Johnsonら[33]とBrunaら[5]は、低レベルのピクセル単位の誤差測定値の代わりに、事前に訓練されたVGGネットワークから抽出された特徴量を使用することを提案している。具体的には、著者らはVGG19 [49]ネットワークから抽出された特徴マップ間のユークリッド距離に基づいて損失関数を定式化している。超解像と芸術的スタイル伝達の両方において、知覚的により説得力のある結果が得られている[19, 20]。最近では、LiとWand[38]もまた、ピクセルまたはVGG特徴空間におけるパッチの比較とブレンドの効果を調査した。

図3：自然画像マニホールドからのパッチ（赤）と、MSE（青）とGAN（オレンジ）で得られた超解像パッチのイラスト。MSEベースの解は、ピクセル空間で可能な解のピクセル単位の平均値のため、過度に滑らかに見えますが、GANは再構成を自然画像マニホールドに向けて駆動し、知覚的により説得力のある解を生み出します。

1.2. 貢献度
GAN は、知覚的に高品質な自然画像を生成するための強力なフレームワークを提供します。GANは、図3に示すように、写実的な画像を含む可能性が高い探索空間の領域に向かって再構成を促し、その結果、自然画像の多様体に近づけることができる。この論文では、フォトリアリスティックSISRのための知覚損失関数を形成するためにGANの概念を使用した最初の非常に深いResNet[29, 30]アーキテクチャについて述べる。我々の主な貢献は以下の通りである。

我々は、MSEのために最適化された16ブロックの深いResNet(SRResNet)を用いて、PSNRと構造的類似性(SSIM)で測定されるような高いアップスケーリング係数(4×)を持つ画像SRのための新しい状態を確立した。

我々は、新しい知覚損失のために最適化されたGANベースのネットワークであるSRGANを提案する。ここでは、MSEベースのコンテンツ損失を、ピクセル空間の変化に対してより不変であるVGGネットワークの特徴マップ[49]に基づいて計算された損失に置き換える[38]。

3つの公開ベンチマークデータセットからの画像を対象とした広範な平均オピニオンスコア(MOS)テストにより、SRGANが高いアップスケーリング係数(4×)を持つフォトリアリスティックなSR画像の推定において、圧倒的な差で新境地であることを確認した。

第2節では、ネットワークアーキテクチャと知覚損失について述べる。第3節では、公開されているベンチマークデータを用いた定量的な評価と視覚的なイラストを提供する。本論文は、第4節での議論と第5節での締めくくりの言葉で締めくくられる。

2. 方法
SISRの目的は、低解像度の入力画像I LRから高解像度の超解像画像I SRを推定することである。ここで、I LRは高解像度の入力画像I HRの低解像度版である。高解像度画像は、訓練中のみ利用可能である。トレーニングでは、I LRはI HRにガウスフィルタを適用し、ダウンサンプリング係数rでダウンサンプリングを行うことで得られる。C色のカラーチャンネルを持つ画像に対して、I LRはW×H×Cサイズの実値テンソルで、I HR, I SRはそれぞれrW×rH×Cで記述する。最終的な目標は、与えられたLR入力画像に対して対応するHRを推定する生成関数Gを訓練することである。これを達成するために、θGをパラメータとするフィードフォワードCNN GθGとして生成ネットワークを訓練する。ここでθG = {W1:L; b1:L}はL層ディープネットワークの重みとバイアスを表し、SR固有の損失関数l SRを最適化することで得られる。学習画像 I HR n , n = 1, ... , N に対応する学習画像 I LR n , n = 1, ... , N については、学習画像 I HR n , n = 1, ... N と対応する I LR n , n = 1, ... , Nに対して、次のように解く。ˆθG = arg min θG 1 N X N n=1 l SR(GθG (I LR n ), IHR n ) (1) 本作業では、具体的には、回復されたSR画像の明瞭な望ましい特性をモデル化するいくつかの損失成分の重み付けされた組み合わせとしての知覚損失l SRを設計する。個々の損失関数については、セクション2.2でより詳細に説明する。

2.1. 逆説ネットワークアーキテクチャ
Goodfellowら[22]に倣って、我々はさらに、GθGと交互に最適化する識別器ネットワークDθDを定義し、敵対的なmin-max問題を解く：min θG max θD EIHR∼ptrain(IHR) [log DθD (I HR)]+ EILR∼pG(ILR) [log(1 - DθD (GθG (I LR))] (2) この定式化の背後にある一般的な考え方は、超解像画像と実画像を区別するために訓練された微分可能な識別器Dを誤魔化すことを目的として、生成モデルGを訓練することができるということである。このアプローチにより、我々の生成器は、実画像に非常に類似した解を生成することを学習することができ、その結果、Dによって分類することが困難になります。これは、MSEのようなピクセル単位の誤差測定値を最小化することによって得られるSR解とは対照的です。図4に示すように、我々の非常に深い生成器ネットワークGの中核には、同一のレイアウトを持つB残差ブロックがあります。Johnsonら[33]にヒントを得て、Gross and Wilber[24]によって提案されたブロックレイアウトを採用しています。具体的には、小さな3×3カーネルと64の特徴マップを持つ2つの畳み込み層を使用し、活性化関数としてバッチ正規化層[32]とParametricReLU[28]が続いています。Shiら[48]が提案したように、2つの訓練されたサブピクセル畳み込み層を使用して入力画像の解像度を上げます。生成されたSRサンプルから実際のHR画像を識別するために、識別ネットワークを訓練します。アーキテクチャを図4に示します。Radfordら[44]がまとめたアーキテクチャ・ガイドラインに従い、LeakyReLU活性化(α = 0.2)を使用し、ネットワーク全体で最大プール化を回避しています。識別器ネットワークは、式2の最大化問題を解くために訓練される。これは、VGGネットワーク[49]のように、64から512カーネルまで2倍に増加する3×3フィルター・カーネルの数が増加する8つの畳み込み層を含んでいる。特徴量の数が2倍になるたびに、画像の解像度を下げるためにストライドコンボリューションが使用されます。結果として得られた512個の特徴マップは、2つの密な層と最終的なシグモイド活性化関数を経て、サンプル分類の確率を得る。

図4: カーネルサイズ(k)、特徴マップの数(n)、ストライド(s)を各畳み込みレイヤーに対応させた生成器・判別器ネットワークのアーキテクチャ。

2.2. 知覚損失関数
我々の知覚損失関数 l SR の定義は、我々の発電機ネットワークの性能にとって非常に重要である。l SR は一般的に MSE [10, 48] に基づいてモデル化されるが、我々は Johnson ら [33] および Bruna ら [5] を改良し、知覚的に関連する特性に関して解を評価する損失関数を設計する。知覚的損失は、コンテンツ損失(l SR X )と逆説的損失成分の加重和として次のように定式化する：l SR = l SR X |{z} コンテンツ損失 + 10-3 l SR Gen | {z } 逆説的損失 | {z } 知覚的損失 (VGGベースのコンテンツ損失の場合) (3) 以下では、コンテンツ損失 l SR X と逆説的損失 l SR Gen の選択可能性について説明します。

2.2.1 コンテンツ損失
ピクセル単位の MSE 損失は次のように計算される： l SR MSE = 1 r 2W H X rW x=1 X rH y=1 (I HR x,y - GθG (I LR)x,y) 2 (4) これは画像 SR の最適化対象として最も広く使用されており、多くの最先端のアプローチがこれに依存している[10, 48]。しかし、MSE 最適化問題の解は、特に高い PSNR を達成する一方で、高周波数コンテンツが不足していることが多く、その結果、知覚的に満足のいかない、滑らかすぎるテクスチャを持つ解となってしまうことがある（図 2 参照）。ピクセル単位の損失に頼るのではなく、Gatysら[19]、Brunaら[5]、Johnsonら[33]のアイデアを基に、知覚的類似度に近い損失関数を使用します。我々は、Simonyan and Zisserman [49]で記述されている事前学習された19層VGGネットワークのReLU活性化層に基づいてVGG損失を定義する。φi,jを用いて、我々は、VGG19層ネットワーク内のi番目のmaxpooling層の前のj番目の畳み込み（活性化後）によって得られた特徴マップを示し、これは与えられたものとみなす。次に、ＶＧＧ損失を、再構成画像ＧθＧ（Ｉ ＬＲ）の特徴表現と参照画像Ｉ ＨＲとの間のユークリッド距離として定義する： l SR V GG/i.j = 1 Wi,jHi,j W Xi,j x=1 H Xi,j y=1 (φi,j (I HR)x,y - φi,j (GθG (I LR))x,y) 2 (5) ここで、Wi,jとHi,jは、ＶＧＧネットワーク内のそれぞれの特徴マップの次元を表す。2.2.2 逆境損失 これまでに説明した内容損失に加えて、知覚損失にGANの生成成分を加える。これは、識別ネットワークを騙そうとすることで、自然画像の多様性に存在する解をネットワークが好むようにすることを促します。生成的損失 l SR Gen は、全学習サンプルに対する識別器 DθD (GθG (I LR)) の確率に基づいて次のように定義される： l SR Gen = X N n=1 - log DθD (GθG (I LR)) (6) ここで、DθD（GθG（I LR））は、再構成画像GθG（I LR）が自然なHR画像である確率である。より良い勾配挙動のために、log[1 - DθD (GθG (I LR))]の代わりに、- log DθD (GθG (I LR))を最小化する[22]。
ここで、Wi,jとHi,jは、VGGネットワーク内のそれぞれの特徴量マップの寸法を表します。

2.2.2 逆説的損失
これまでに説明したコンテンツの損失に加えて、我々のGANの生成的なコンポーネントを知覚的な損失に追加する。これは、識別ネットワークを騙そうとすることで、自然画像の多様性に存在する解をネットワークが好むようにすることを促します。生成的損失 l SR Gen は、全学習サンプルに対する識別器 DθD (GθG (I LR)) の確率に基づいて次のように定義される： l SR Gen = X N n=1 - log DθD (GθG (I LR)) (6) ここで、DθD（GθG（I LR））は、再構成画像GθG（I LR）が自然なHR画像である確率である。より良い勾配挙動のために、log[1 - DθD (GθG (I LR))]の代わりに、- log DθD (GθG (I LR))を最小化する[22]。

3. 実験
3.1. データと類似性対策
我々は，広く利用されている3つのベンチマークデータセットSet5 [3]，Set14 [69]，BSD300 [41]のテストセットであるBSD100を用いて実験を行う．すべての実験は，低解像度画像と高解像度画像の間のスケールファクタを4×にして行われる．これは、画像ピクセルの16×縮小に相当する。公正な比較のために，報告されているPSNR [dB] と SSIM [58] の測定値はすべて，各境界から4ピクセル幅のストリップを除去したセンタークロップされた画像のyチャンネルについて，daalaパッケージを用いて計算されています1．最近傍法、双曲線法、SRCNN [9] および SelfExSR [31] を含む参照法の超解像画像は、Huang et al.2 [31] の補足資料から、DRCN については Kim et al.3 [34] のオンライン資料から入手した。SRResNet（損失：l SR MSEおよびl SR V GG/2.2）およびSRGANバリアントで得られた結果は、オンラインで入手可能である4 。統計的検定は、対をなす両側Wilcoxon符号付き順位検定として実施され、有意性はp < 0.05で決定された。読者は、GitHub上で独自に開発されたGANベースのソリューションにも興味があるかもしれません5 。しかし、これは限られた顔のセットでの実験結果を提供しているに過ぎず、より制約が多く、より簡単なタスクです。

3.2. 学習の詳細とパラメータ
ImageNetデータベース[45]から35万枚の画像のランダムサンプルを使用して、NVIDIA Tesla M40 GPU上ですべてのネットワークを学習しました。これらの画像は、テスト画像とは区別されている。HR画像(BGR, C = 3)をダウンサンプリング係数r = 4の二次関数カーネルを用いてダウンサンプリングしてLR画像を得た。各ミニバッチについて、異なる訓練画像のランダムな96×96のHRサブ画像を16枚切り出した。ジェネレータモデルは完全に畳み込みであるため、任意のサイズの画像に適用できることに注意してください。LR入力画像の範囲を[0, 1]に、HR画像の範囲を[-1, 1]にスケーリングした。このようにして、強度範囲[-1, 1]の画像についてMSE損失を計算した。また、VGG特徴量マップは、MSE損失と同等のスケールのVGG損失を得るために、1 12.75のファクタで再スケーリングされた。これは、≈0.006の再スケーリング係数で式5を乗算することと同等です。最適化のために、我々はβ1 = 0.9でAdam [36]を使用します。SRResNetネットワークは、10-4の学習率と106回の更新反復で訓練されました。望ましくない局所最適化を避けるために、実際のGANを訓練する際に、ジェネレータの初期化として訓練されたMSEベースのSRResNetネットワークを採用しました。すべてのSRGANバリアントは、学習率10-4で105回の更新を繰り返し、さらに10-5で105回の更新を繰り返して学習した。これは、Goodfellowら[22]で使用されているk = 1に相当する。このジェネレータ・ネットワークは、16個の同一の（B = 16）残差ブロックを持っています。テスト時には、バッチ正規化更新をオフにして、入力のみに決定論的に依存する出力を得る [32]。我々の実装は、Theano [53]とLasagne [8]に基づいています。


3.4. コンテンツ損失の調査
GAN ベースのネットワークにおいて、コンテンツ損失の選択が知覚損失に与える影響を調査した。具体的には、以下のコンテンツ損失 l SR X について、l SR = l SR X + 10-3 l SR Gen を調査した。

表1: Set5とSet14のベンチマークデータ上でのSRResNetと敵対者ネットワークの異なる損失関数の性能。MOS スコアは、そのカテゴリーの他の損失と比較して有意に高い（p < 0.05）。4×アップスケーリング

- SRGAN-MSE: l SR MSE, 標準的なMSEをコンテンツ損失として用いて敵対ネットワークを調査する。
- SRGAN-VGG22: l SR V GG/2.2 with φ2,2,2, 下位レベルの特徴を表す特徴マップ上で定義された損失[68]。
- SRGAN-VGG54: l SR V GG/5.4、φ5,4のSR V GG/5.4、画像のコンテンツに焦点を当てる可能性の高い、より深いネットワーク層からのより高いレベルの特徴の特徴マップに定義された損失 [68, 65, 40]。以下では、このネットワークをSRGANと呼ぶ。

また、2つの損失l SR MSE(SRResNet-MSE)とl SR V GG/2.2(SRResNet-VGG22)について、対向成分を含まない発電機ネットワークの性能を評価した。ここでは、SRResNet-MSEをSRResNetと呼ぶ。SRResNet-VGG22を学習する際に、我々はl SR V GG/2.2 [2, 33]に2×10-8の重みで総変動損失を追加したことに注意してください。定量的な結果を表1にまとめ、図6に視覚的な例を示す。敵対的損失と組み合わせても、MSEは最高のPSNR値を持つ解を提供しますが、知覚的にはむしろ滑らかで、視覚知覚に敏感な損失成分で達成された結果よりも説得力がありません。これは、MSEに基づいたコンテンツ損失と敵対的損失との間の競合が原因である。さらに、SRGANMSEベースの再構成の少数派で見られた小さな再構成アーチファクトは、これらの競合する目的に起因していると考えられます。Set5では、MOSスコアに関してSRResNetやSRGANの有意に最適な損失関数を決定することはできなかったが、Set14ではSRGAN-VGG54がMOSの点で他のSRGANやSRResNetのバリアントを有意に上回っていた。また、高レベルのVGG特徴マップφ5,4を使用することで、φ2,2に比べてテクスチャの詳細度が向上する傾向が見られました（図6参照）。SRResNetよりもSRGANによる知覚改善の例は、補足資料に記載されています。

図5：BSD100におけるMOSスコアの色分け分布。各手法で2600サンプル(100画像×26レイター)を評価した。平均値は赤いマーカーで示され、ビンは値iを中心にしています。

3.5. 最終的なネットワークの性能
我々は、SRResNetとSRGANの性能をNN、双曲線補間、および4つの最新手法と比較した。定量的な結果は表2にまとめられており、SRResNet（PSNR/SSIMの観点から）が3つのベンチマークデータセット上で新たな技術を確立していることが確認された。評価には一般に公開されているフレームワークを使用しているため（3.1節参照）、報告されている値は原著論文で報告されている値とは若干異なる可能性があることに注意してください。さらに、SRGANとすべての参照手法について、BSD100上でMOS評価を取得しました。SRResNetとSRGANで超解像した画像の例を補足資料に示します。表2に示された結果から、SRGANはすべての参照手法を大差で凌駕し、フォトリアリスティック画像SRのための新境地を切り開いたことが確認されました。表2に示す結果は、SRCNN対SelfExSRを除くすべてのMOSの違いが、BSD100上で非常に有意であることを示している。収集したすべてのMOS評価の分布を図5にまとめました。

図6：SRResNet（左：a,b）、SRGAN-MSE（左中：c,d）、SRGAN-VGG2.2（中：e,f）、SRGAN-VGG54（中右：g,h）の再構成結果と対応する参照HR画像（右：i,j）。4×アップスケーリング 

表2: NN、bicubic、SRCNN [9]、SelfExSR [31]、DRCN [34]、ESPCN [48]、SRResNet、SRGAN-VGG54、およびベンチマークデータ上のオリジナルHRの比較。太字で表示されているのは、最も高い測定値(PSNR [dB]、SSIM、MOS)です。4×アップスケーリング

4. 考察と今後の課題
我々はMOSテストを用いてSRGANの優れた知覚性能を確認した。さらに、PSNRやSSIMなどの標準的な定量的な尺度では、人間の視覚システムに関して画像品質を捕捉し、正確に評価することができないことを示しました[56]。この研究では、計算効率よりも超解像画像の知覚品質に焦点を当てました。Shiら[48]とは対照的に、提示されたモデルはリアルタイムでのビデオSRに最適化されていない。しかし、ネットワークアーキテクチャに関する予備的な実験では、浅いネットワークが定性的な性能をわずかに低下させるだけで、非常に効率的な代替手段を提供する可能性があることが示唆されている。Dongら[10]とは対照的に、我々はより深いネットワークアーキテクチャが有益であることを発見した。我々は、ResNet の設計がより深いネットワークの性能に大きな影響を与えていると推測しています。我々は、より深いネットワーク(B>16)でもSRResNetの性能をさらに向上させることができることを発見したが、その代償としてトレーニングとテストの時間が長くなることを発見した(補足資料参照)。さらに、より深いネットワークのSRGANの変種は、高周波数のアーチファクトが出現するため、訓練がますます困難になることを発見した。

SR問題をフォトリアリスティックに解決するためには、図6に示すように、コンテンツロスの選択が特に重要である。この研究では、l SR V GG/5.4が知覚的に最も説得力のある結果をもたらしていることを発見した。我々は、これらの深層ネットワーク層の特徴マップが純粋にコンテンツに焦点を当てている一方で、逆説的損失は、逆説的損失のない超解像画像と写真のようにリアルな画像との主な違いであるテクスチャの詳細に焦点を当てていると推測しています。また、理想的な損失関数はアプリケーションに依存することにも注意が必要です。例えば、より微細なディテールを幻覚化するようなアプローチは、医療用途や監視用途にはあまり適していないかもしれません。テキストや構造化されたシーンの知覚的に説得力のある再構成 [31] は挑戦的であり、今後の研究の一部である。画像の空間的な内容を記述するが、ピクセル空間の変化に対してより不変な内容損失関数の開発は、フォトリアリスティックな画像SRの結果をさらに向上させるであろう。

5.結論 
我々は、広く使われているPSNR測定値を用いて評価した場合に、公開ベンチマークデータセット上で新たな状態を確立する深層残差ネットワークSRResNetを記述した。我々は、このPSNRに焦点を当てた画像超解像のいくつかの限界を強調し、GANを訓練することにより、コンテンツロス関数を敵対的損失で補強するSRGANを導入した。広範なMOSテストを用いて、大きなアップスケーリング係数(4×)のSRGAN再構成が、最新の参照手法を用いて得られた再構成よりも、かなりの差で写真のようにリアルであることを確認しました。





