{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path as osp\n",
    "import math\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torchvision.models import vgg19\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class opts():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = opts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.channles = 3\n",
    "opt.hr_height = 128\n",
    "opt.residual_blocks = 23\n",
    "opt.lr = 0.0002\n",
    "opt.b1 = 0.9\n",
    "opt.b2 = 0.999\n",
    "opt.batch_size = 4\n",
    "opt.n_cpu = 8\n",
    "opt.n_epoch = 200\n",
    "opt.warmup_batches = 500\n",
    "# opt.warmup_batches = 5\n",
    "opt.lambda_adv = 5e-3\n",
    "opt.lambda_pixel = 1e-2\n",
    "\n",
    "opt.pretrained = False\n",
    "\n",
    "opt.dataset_name = 'cat'\n",
    "# opt.dataset_name = 'img_align_celeba_resize'\n",
    "# opt.dataset_name = 'img_align_celeba_resize'\n",
    "\n",
    "opt.sample_interval = 50\n",
    "opt.checkpoint_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [arg for arg in dir(opt) if not arg.startswith('__')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_dict = {arg: getattr(opt, arg) for arg in args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_shape = (opt.hr_height, opt.hr_height)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseResidualBlock(nn.Module):\n",
    "    def __init__(self, filters, res_scale=0.2):\n",
    "        super(DenseResidualBlock, self).__init__()\n",
    "        self.res_scale = res_scale\n",
    "        \n",
    "        def block(in_features, non_linearity=True):\n",
    "            layers = [nn.Conv2d(in_features, filters, 3, 1, 1, bias=True)]\n",
    "            if non_linearity:\n",
    "                layers += [nn.LeakyReLU()]\n",
    "            return nn.Sequential(*layers)\n",
    "    \n",
    "        self.b1 = block(in_features=1 * filters)\n",
    "        self.b2 = block(in_features=2 * filters)\n",
    "        self.b3 = block(in_features=3 * filters)\n",
    "        self.b4 = block(in_features=4 * filters)\n",
    "        self.b5 = block(in_features=5 * filters, non_linearity=False)\n",
    "        self.blocks = [self.b1, self.b2, self.b3, self.b4, self.b5]\n",
    "    \n",
    "    def forward(self, x):\n",
    "        inputs = x\n",
    "        for block in self.blocks:\n",
    "            out = block(inputs)\n",
    "            inputs = torch.cat([inputs, out], 1)\n",
    "        return out.mul(self.res_scale) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualInResidualDenseBlock(nn.Module):\n",
    "    def __init__(self, filters, res_scale=0.2):\n",
    "        super(ResidualInResidualDenseBlock, self).__init__()\n",
    "        self.res_scale = res_scale\n",
    "        self.dense_blocks = nn.Sequential(\n",
    "            DenseResidualBlock(filters), DenseResidualBlock(filters), DenseResidualBlock(filters)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.dense_blocks(x).mul(self.res_scale) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorPRDB(nn.Module):\n",
    "    def __init__(self, channels, filters=64, num_res_blocks=16, num_upsample=2):\n",
    "        super(GeneratorPRDB, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(channels, filters, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.res_blocks = nn.Sequential(*[ResidualInResidualDenseBlock(filters) for _ in range(num_res_blocks)])\n",
    "        self.conv2 = nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        upsample_layers = []\n",
    "        \n",
    "        for _ in range(num_upsample):\n",
    "            upsample_layers += [\n",
    "                nn.Conv2d(filters, filters * 4, kernel_size=3, stride=1, padding=1),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.PixelShuffle(upscale_factor=2),\n",
    "            ]\n",
    "        self.upsampling = nn.Sequential(*upsample_layers)\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(filters, filters, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(filters, channels, kernel_size=3, stride=1, padding=1),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.conv1(x)\n",
    "        out = self.res_blocks(out1)\n",
    "        out2 = self.conv2(out)\n",
    "        out = torch.add(out1, out2)\n",
    "        out = self.upsampling(out)\n",
    "        out = self.conv3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        vgg19_model = vgg19(pretrained=True)\n",
    "        self.vgg19_54 = nn.Sequential(*list(vgg19_model.features.children())[:35])\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.vgg19_54(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "                \n",
    "        self.input_shape = input_shape\n",
    "        in_channels, in_height, in_width = self.input_shape\n",
    "        patch_h, patch_w = int(in_height / 2 ** 4), int(in_width / 2 ** 4)\n",
    "        self.output_shape = (1, patch_h, patch_w)\n",
    "    \n",
    "        def descriminator_block(in_filters, out_filters, first_block=False):\n",
    "            layers = []\n",
    "            layers.append(nn.Conv2d(in_filters, out_filters, kernel_size=3, stride=1, padding=1))\n",
    "            if not first_block:\n",
    "                layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            layers.append(nn.Conv2d(out_filters, out_filters, kernel_size=3, stride=2, padding=1))\n",
    "            layers.append(nn.BatchNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        layers = []\n",
    "        in_filters = in_channels\n",
    "        for i, out_filters in enumerate([64, 128, 256, 512]):\n",
    "            print(descriminator_block(in_filters, out_filters, first_block=(i == 0)))\n",
    "            layers.extend(descriminator_block(in_filters, out_filters, first_block=(i == 0)))\n",
    "            in_filters = out_filters\n",
    "        \n",
    "        layers.append(nn.Conv2d(out_filters, 1, kernel_size=3, stride=1, padding=1))\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensors):\n",
    "    for c in range(3):\n",
    "        tensors[:, c].mul_(std[c]).add_(mean[c])\n",
    "    return torch.clamp(tensors, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, dataset_dir, hr_shape):\n",
    "        hr_height, hr_width = hr_shape\n",
    "        \n",
    "        self.lr_transform = transforms.Compose([\n",
    "            transforms.Resize((hr_height // 4, hr_height // 4), Image.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)])\n",
    "\n",
    "        self.hr_transform = transforms.Compose([\n",
    "            transforms.Resize((hr_height, hr_height), Image.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)])\n",
    "        \n",
    "        self.files = sorted(glob(osp.join(dataset_dir, '*')))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "        img_lr = self.lr_transform(img)\n",
    "        img_hr = self.hr_transform(img)\n",
    "        \n",
    "        return {'lr': img_lr, 'hr': img_hr}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestImageDataset(Dataset):\n",
    "    def __init__(self, dataset_dir):\n",
    "        # TODO: 入力に対して1/4\n",
    "        self.hr_transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean, std)])\n",
    "        self.files = sorted(glob(osp.join(dataset_dir, '*')))\n",
    "    \n",
    "    def lr_transform(self, img, img_size):\n",
    "        img_width, img_height = img_size\n",
    "        self.__lr_transform = transforms.Compose([\n",
    "            transforms.Resize((img_height // 4, img_width // 4), Image.BICUBIC),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)])\n",
    "        img = self.__lr_transform(img)\n",
    "        return img\n",
    "            \n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.files[index % len(self.files)])\n",
    "        img_size = img.size\n",
    "        img_lr = self.lr_transform(img, img_size)\n",
    "        img_hr = self.hr_transform(img)\n",
    "        \n",
    "        return {'lr': img_lr, 'hr': img_hr}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(label, save_path):\n",
    "    f = open(save_path, \"w\")\n",
    "    json.dump(label, f, ensure_ascii=False, indent=4, \n",
    "              sort_keys=True, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = osp.join(ROOT, 'input')\n",
    "output_dir = osp.join(ROOT, 'output', str(datetime.datetime.fromtimestamp(time.time())))\n",
    "weight_dir = osp.join(ROOT, 'weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train_save_dir = osp.join(output_dir, 'image', 'train')\n",
    "image_test_save_dir = osp.join(output_dir, 'image', 'test')\n",
    "weight_save_dir = osp.join(output_dir, 'weight')\n",
    "\n",
    "os.makedirs(image_train_save_dir, exist_ok=True)\n",
    "os.makedirs(image_test_save_dir, exist_ok=True)\n",
    "os.makedirs(weight_save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = osp.join(input_dir, '{}_train'.format(opt.dataset_name))\n",
    "test_data_dir = osp.join(input_dir, '{}_test_sub2'.format(opt.dataset_name))\n",
    "g_weight_path = osp.join(weight_dir, 'generator.pth')\n",
    "d_weight_path = osp.join(weight_dir, 'discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_save_path = osp.join(output_dir, 'opt.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(opt_dict, opt_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), LeakyReLU(negative_slope=0.2, inplace=True), Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), LeakyReLU(negative_slope=0.2, inplace=True)]\n",
      "[Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), LeakyReLU(negative_slope=0.2, inplace=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), LeakyReLU(negative_slope=0.2, inplace=True)]\n",
      "[Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), LeakyReLU(negative_slope=0.2, inplace=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), LeakyReLU(negative_slope=0.2, inplace=True)]\n",
      "[Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), LeakyReLU(negative_slope=0.2, inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)), BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), LeakyReLU(negative_slope=0.2, inplace=True)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FeatureExtractor(\n",
       "  (vgg19_54): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (17): ReLU(inplace=True)\n",
       "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (24): ReLU(inplace=True)\n",
       "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (26): ReLU(inplace=True)\n",
       "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (31): ReLU(inplace=True)\n",
       "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (33): ReLU(inplace=True)\n",
       "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = GeneratorPRDB(opt.channles, filters=64, num_res_blocks=opt.residual_blocks).to(device)\n",
    "discriminator = Discriminator(input_shape=(opt.channles, *hr_shape)).to(device)\n",
    "\n",
    "if opt.pretrained:\n",
    "    generator.load_state_dict(torch.load(g_weight_path))\n",
    "    discriminator.load_state_dict(torch.load(d_weight_path))\n",
    "\n",
    "feature_extractor = FeatureExtractor().to(device)\n",
    "feature_extractor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_GAN = nn.BCEWithLogitsLoss().to(device)\n",
    "criterion_content = nn.L1Loss().to(device)\n",
    "criterion_pixel = nn.L1Loss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_G = optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    ImageDataset(train_data_dir, hr_shape=hr_shape),\n",
    "    batch_size=opt.batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=opt.n_cpu,\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    TestImageDataset(test_data_dir),\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=opt.n_cpu,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "loss_names = ['batch_num', 'loss_pixel', 'loss_D', 'loss_G', 'loss_content', 'loss_GAN']\n",
    "train_infos = []\n",
    "\n",
    "plt.figure(figsize=(16,9))\n",
    "low_image_save = False\n",
    "\n",
    "for epoch in range(1, opt.n_epoch + 1):\n",
    "    for batch_num, imgs in enumerate(train_dataloader):\n",
    "        batches_done = (epoch - 1) * len(train_dataloader) + batch_num\n",
    "        \n",
    "        # preprocess\n",
    "        imgs_lr = Variable(imgs['lr'].type(Tensor))\n",
    "        imgs_hr = Variable(imgs['hr'].type(Tensor))\n",
    "        \n",
    "        # ground truth\n",
    "        valid = Variable(Tensor(np.ones((imgs_lr.size(0), *discriminator.output_shape))), \n",
    "                         requires_grad=False)\n",
    "        fake = Variable(Tensor(np.zeros((imgs_lr.size(0), *discriminator.output_shape))), \n",
    "                        requires_grad=False)\n",
    "        \n",
    "        # バックプロパゲーションの前に勾配を０にする\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # 低解像度の画像から高解像度の画像を生成\n",
    "        gen_hr = generator(imgs_lr)\n",
    "        \n",
    "        loss_pixel = criterion_pixel(gen_hr, imgs_hr)\n",
    "        \n",
    "        # 画素単位の損失であるloss_pixelで事前学習を行う\n",
    "        if batches_done <= opt.warmup_batches:\n",
    "            loss_pixel.backward()\n",
    "            optimizer_G.step()\n",
    "            train_info = {\n",
    "                'epoch': epoch, \n",
    "                'batch_num': batch_num,\n",
    "                'loss_pixel': loss_pixel.item()\n",
    "            }\n",
    "        \n",
    "            sys.stdout.write('\\r{}'.format('\\t'*10))\n",
    "            sys.stdout.write('\\r {}'.format(train_info))            \n",
    "        else:\n",
    "        \n",
    "            # prediction\n",
    "            pred_real = discriminator(imgs_hr).detach()\n",
    "            pred_fake = discriminator(gen_hr)\n",
    "\n",
    "            # Aeversarial loss\n",
    "            loss_GAN = criterion_GAN(pred_fake - pred_real.mean(0, keepdim=True), valid)\n",
    "\n",
    "            # content loss(perceptual loss)\n",
    "            # 特徴抽出機で抽出した特徴を用いて生成画像と本物画像のL1距離を算出\n",
    "            gen_feature = feature_extractor(gen_hr)\n",
    "            real_feature = feature_extractor(imgs_hr).detach()\n",
    "            loss_content = criterion_content(gen_feature, real_feature)\n",
    "\n",
    "            # Total generator loss\n",
    "            loss_G = loss_content + opt.lambda_adv * loss_GAN + opt.lambda_pixel * loss_pixel\n",
    "\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            pred_real = discriminator(imgs_hr)\n",
    "            pred_fake = discriminator(gen_hr.detach())\n",
    "\n",
    "            # adversarial loss\n",
    "            loss_real = criterion_GAN(pred_real - pred_fake.mean(0, keepdim=True), valid)\n",
    "            loss_fake = criterion_GAN(pred_fake - pred_real.mean(0, keepdim=True), fake)\n",
    "\n",
    "            loss_D = (loss_real + loss_fake) / 2\n",
    "\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            train_info = {\n",
    "                'epoch': epoch,\n",
    "                'epoch_total': opt.n_epoch,\n",
    "                'batch_num': batch_num, \n",
    "                'batch_total': len(train_dataloader),\n",
    "                'loss_D': loss_D.item(),\n",
    "                'loss_G': loss_G.item(),\n",
    "                'loss_content': loss_content.item(),\n",
    "                'loss_GAN': loss_GAN.item(),\n",
    "                'loss_pixel': loss_pixel.item(),\n",
    "            }\n",
    "\n",
    "            if batch_num == 1:\n",
    "                sys.stdout.write('\\n{}'.format(train_info))\n",
    "            else:\n",
    "                sys.stdout.write('\\r{}'.format('\\t'*20))\n",
    "                sys.stdout.write('\\r{}'.format(train_info))\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        train_infos.append(train_info)\n",
    "        \n",
    "        if batches_done % opt.sample_interval == 0:\n",
    "            # Save image grid with upsampled inputs and ESRGAN outputs\n",
    "            imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)\n",
    "            img_grid = denormalize(torch.cat((imgs_lr, gen_hr), -1))\n",
    "\n",
    "            image_batch_save_dir = osp.join(image_train_save_dir, '{:07}'.format(batches_done))\n",
    "            os.makedirs(osp.join(image_batch_save_dir, \"hr_image\"), exist_ok=True)\n",
    "            save_image(img_grid, osp.join(image_batch_save_dir, \"hr_image\", \"%d.png\" % batches_done), nrow=1, normalize=False)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for i, imgs in enumerate(test_dataloader):\n",
    "                    # Save image grid with upsampled inputs and outputs\n",
    "                    imgs_lr = Variable(imgs[\"lr\"].type(Tensor))\n",
    "                    gen_hr = generator(imgs_lr)\n",
    "                    imgs_lr = nn.functional.interpolate(imgs_lr, scale_factor=4)\n",
    "\n",
    "                    imgs_lr = denormalize(imgs_lr)\n",
    "                    gen_hr = denormalize(gen_hr)\n",
    "\n",
    "                    image_batch_save_dir = osp.join(image_test_save_dir, '{:03}'.format(i))\n",
    "                    os.makedirs(osp.join(image_batch_save_dir, \"hr_image\"), exist_ok=True)\n",
    "                    save_image(gen_hr, osp.join(image_batch_save_dir, \"hr_image\", \"{:09}.png\".format(batches_done)), nrow=1, normalize=False)\n",
    "                    if not low_image_save:\n",
    "                        save_image(imgs_lr, osp.join(image_batch_save_dir, \"lr_image.jpg\"), nrow=1, normalize=False)\n",
    "            low_image_save = True\n",
    "                    \n",
    "\n",
    "        if batches_done % opt.checkpoint_interval == 0:            \n",
    "            # Save model checkpoints\n",
    "            torch.save(generator.state_dict(), osp.join(weight_save_dir, \"generator_%d.pth\" % batches_done))\n",
    "            torch.save(discriminator.state_dict(), osp.join(weight_save_dir, \"discriminator_%d.pth\" % batches_done))\n",
    "        \n",
    "        log_df = pd.DataFrame(train_infos)\n",
    "        log_df = log_df.set_index('batch_num')\n",
    "        cols = log_df.columns[log_df.columns.isin(loss_names)]\n",
    "        log_df = log_df[cols]\n",
    "                \n",
    "        for num, loss_name in enumerate(log_df.columns, 1):\n",
    "            plt.subplot(2, 3, num)\n",
    "            plt.plot(log_df.index.values, log_df[loss_name].values, marker='o', color='b')\n",
    "            plt.title(loss_name)\n",
    "        \n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.4.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
